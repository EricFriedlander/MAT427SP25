{
  "hash": "559f87a501cd1fad5f2d4e00e23318a5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'MAT-427: Multiple Linear Regression + Data Splitting'\nauthor: Eric Friedlander\nfooter: \"[ðŸ”— MAT 427 - Spring 2025 -  Schedule](https://mat427sp25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\n---\n\n\n\n\n\n## Multiple Linear Regression\n\n- Response: $Y$\n- Predictor Variables: $X_1, X_2, \\ldots, X_p$\n- Assume true relationship:\n\n$$\n\\begin{aligned}\nY&=f(\\mathbf{X}) + \\epsilon\\\\\n&=\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_p X_p + \\epsilon\n\\end{aligned}\n$$\nwhere $\\beta_j$ quantifies the association between the $j^{th}$ predictor and the response.\n\n\n\n## [Multiple Linear Regression: Estimating Parameters]{.r-fit-text} {.smaller}\n\n- Suppose $\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p$ are estimates of $\\beta_0, \\beta_1, \\ldots, \\beta_p$\n- Training Data:\n  + Observed response: $y_i$ for $i=1,\\ldots,n$\n  + Observed predictors: $x_{1i}, x_{2i}, \\ldots x_{pi}$ for $i=1,\\ldots, n$\n- Predicted response: \n$$\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{1i} + \\ldots + \\hat{\\beta}_px_{pi} \\text{ for } i=1, \\ldots, n$$\n- Residuals: $e_i = \\hat{y}_i - y_i$ for $i=1, \\ldots, n$\n- Mean Squared Error (MSE): $MSE =\\dfrac{e^2_1+e^2_2+\\ldots+e^2_n}{n}$\n\n## [Multiple Linear Regression: Estimating Parameters]{.r-fit-text}\n\n- **Goal:** Use *training data* to find $\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p$ that minimizes MSE\n  + $\\hat{\\beta}_i$'s called **least-squares estimators**\n  + Since minimizing MSE $\\implies$ MSE is called **cost/loss function**\n- Can use calculus or gradient descent to find $\\hat{\\beta}_i$'s\n\n\n\n## Multiple Linear Regression\n\n- **House Prices dataset:**\n  + `size` is in square feet\n  + `num_bedrooms` is a count\n  + `price` is in $1,000's\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhouse_prices <- readRDS(\"../data/house_prices.rds\")   # load dataset\nhead(house_prices, 6)   # print first 6 observations\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  size num_bedrooms price\n1 2104            3 399.9\n2 1600            3 329.9\n3 2400            3 369.0\n4 1416            2 232.0\n5 3000            4 539.9\n6 1985            4 299.9\n```\n\n\n:::\n:::\n\n\n\n\n## Multiple Linear Regression\n\nSome Exploratory Data Analysis (EDA)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(GGally)\nggpairs(data = house_prices)   # correlation plot\n```\n\n::: {.cell-output-display}\n![](04-MultipleRegression_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n## Multiple Linear Regression in R {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_model <- lm(price ~ size + num_bedrooms, data = house_prices)   # fit the model\nsummary(mlr_model)   # produce result summaries of the model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = price ~ size + num_bedrooms, data = house_prices)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-130.58  -43.64  -10.83   43.70  198.15 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   89.5978    41.7674   2.145   0.0375 *  \nsize           0.1392     0.0148   9.409 4.22e-12 ***\nnum_bedrooms  -8.7379    15.4507  -0.566   0.5746    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 66.07 on 44 degrees of freedom\nMultiple R-squared:  0.7329,\tAdjusted R-squared:  0.7208 \nF-statistic: 60.38 on 2 and 44 DF,  p-value: 2.428e-13\n```\n\n\n:::\n:::\n\n\n\n## [Multiple Linear Regression: Interpreting Parameters]{.r-fit-text} {.smaller}\n\n- $\\hat{\\beta}_0=89.5978$: The intercept $\\implies$ a house with 0 square feet and 0 bedrooms would cost approximately \\$89,598.80. Is this meaningful in context? [Not really]{.fragment .fade-in}\n- $\\hat{\\beta}_1=0.1392$: With `num_bedrooms` remaining fixed, an additional 1 square foot of `size` leads to an increase in `price` by approximately \\$139.20.\n- $\\hat{\\beta}_2=-8.7379$: With `size` remaining fixed, an additional bedroom leads to an decrease in `price` of approximately \\$8,737.90.\n\n. . .\n\n- Hmm.... that's a little weird...\n- **Simpson's Paradox:** when relationship between two variables disappears or reverses when controlling for a third, **confounding variable**\n\n## [Multiple Linear Regression: Interpreting Parameters]{.r-fit-text}\n\n:::{.incremental}\n- Write down our model in mathematical notation\n- $\\text{sales} = 89.5978 + 0.1392\\times\\text{size} - 8.7379\\times\\text{num_bedrooms}$\n- $Y = 89.5978 + 0.1392X_1 - 8.7379X_2$\n:::\n\n\n## Multiple Linear Regression: Prediction {.smaller}\n\n- Prediction of `price` when `size` is 2000 square feet for a house with 3 bedrooms\n- $\\text{sales} = 89.5978 + 0.1392\\times2000 - 8.7379\\times3 = 341.7841$\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(mlr_model, newdata = data.frame(size = 2000, num_bedrooms = 3))   # obtain prediction\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1 \n341.8053 \n```\n\n\n:::\n:::\n\n\n- Why don't these match exactly? [**rounding**]{.fragment .fade-in}\n\n\n## Linear Regression: Comparing Models {.smaller}\n\n:::{.fragment}\n:::{.incremental}\n- Many methods for comparing regression models from your regression course\n- Today: Data splitting\n- First: New Data\n:::\n:::\n:::{.fragment}\n- **ames housing data**\n  + Many variables\n  + Focus on:\n    * `Sale_Price`: in dollars\n    * `Gr_Liv_Area`: size in square feet\n    * `Bedroom_AbvGr`: number of bedrooms above grade\n:::\n\n\n\n## Comparing Models: Data Splitting {.smaller}\n\n- Split `ames` data set into two parts\n  + Training set: randomly selected proportion $p$ (typically 50-90%) of data used for fitting model\n  + Test set: randomly selected proportion $1-p$ of data used for estimating prediction error\n- If comparing A LOT of models, split into *three* parts to prevent **information leakage**\n  + Training set: randomly selected proportion $p$ (typically 50-90%) of data used for fitting model\n  + Validation set: randomly selected proportion $q$ (typically 20-30%) of data used to choosing tuning parameters\n  + Test set: randomly selected proportion $1-p-q$ of data used for estimating prediction error\n- Idea: use data your model hasn't seen to get more accurate estimate of error and prevent overfitting\n\n## Comparing Models: Data Splitting with R {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splitTools) # Load data splitting package\nindicies <- partition(ames$Sale_Price, p = c(train = 0.7, test = 0.3)) # get indices of partitions\ntrain_ames <- ames[indicies$train, ] # names will mimic above\ntest_ames <- ames[indicies$test, ]\n```\n:::\n\n\n\n- `partition` will actually stratify based on it's first argument (`Sales_Price` in this case)\n\n## Linear Regression: Comparing Models {.smaller}\n\n- Let's create three models with `Sale_Price` as the response:\n  + **fit1**: a linear regression model with `Bedroom_AbvGr`  as the only predictor\n  + **fit2**: a linear regression model with `Gr_Liv_Area` as the only predictor\n  + **mlr_model** (similar to model in previous slides): a multiple regression model with `Gr_Liv_Area` and `Bedroom_AbvGr` as predictors\n  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- lm(Sale_Price ~ Bedroom_AbvGr, data=train_ames) # Use only training set\nfit2 <- lm(Sale_Price ~ Gr_Liv_Area, data = train_ames) \nmlr_model <- lm(Sale_Price ~ Gr_Liv_Area + Bedroom_AbvGr, data = train_ames)\n```\n:::\n\n\n\n## Computing Error Metrics {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit 1\nfit1_train_mse <- mean((train_ames$Sale_Price - predict(fit1))^2)\nfit1_test_mse <- mean((test_ames$Sale_Price - predict(fit1, newdata = test_ames))^2)\n\n# Fit 2\nfit2_train_mse <- mean((train_ames$Sale_Price - predict(fit2))^2)\nfit2_test_mse <- mean((test_ames$Sale_Price - predict(fit2, newdata = test_ames))^2)\n\n# Fit 1\nmlr_train_mse <- mean((train_ames$Sale_Price - predict(mlr_model))^2)\nmlr_test_mse <- mean((test_ames$Sale_Price - predict(mlr_model, new_data = testames))^2)\n```\n:::\n\n\n\n## [Question]{style=\"color:blue\"}\n\n1. Do we know which of the following is the smallest: `fit1_train_mse`, `fit2_train_mse`, `mlr_train_mse`? [Yes, `mlr_train_mse`]{.fragment .fade-in}\n2. Do we know which of the following is the smallest: `fit1_test_mse`, `fit2_test_mse`, `mlr_test_mse`? [No]{.fragment .fade-in}\n\n## Choosing a Model {.smaller}\n\n::::{.columns}\n:::{.column}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Training Errors\nfit1_train_mse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6130313692\n```\n\n\n:::\n\n```{.r .cell-code}\nfit2_train_mse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3174284112\n```\n\n\n:::\n\n```{.r .cell-code}\nmlr_train_mse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2756716299\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.min(c(fit1_train_mse, fit2_train_mse, mlr_train_mse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n\n```{.r .cell-code}\n# test Errors\nfit1_test_mse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6520779039\n```\n\n\n:::\n\n```{.r .cell-code}\nfit2_test_mse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3238693457\n```\n\n\n:::\n\n```{.r .cell-code}\nmlr_test_mse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9922647922\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.min(c(fit1_test_mse, fit2_test_mse, mlr_test_mse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n:::\n\n\n:::\n:::{.column}\n- `mlr_model` has the lowest training MSE (to be expected)\n- `fit2` has the lowest test MSE\n  + We would choose `fit2`\n- Anything else interesting we seee?\n:::\n::::\n\n\n## Regression: Conditional Averaging\n\n**Restaurant Outlets Profit dataset**\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04-MultipleRegression_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n\nWhat is a good value of $\\hat{f}(x)$ (expected profit), say at $x=6$?\n\nA possible choice is the **average of the observed responses** at $x=6$. But we may not observe responses for certain $x$ values.\n\n\n## K-Nearest Neighbors (KNN) Regression  {.smaller}\n\n- Non-parametric approach\n- Formally: Given a value for $K$ and a test data point $x_0$,\n$$\\hat{f}(x_0)=\\dfrac{1}{K} \\sum_{x_i \\in \\mathcal{N}_0} y_i=\\text{Average} \\ \\left(y_i \\ \\text{for all} \\ i:\\ x_i \\in \\mathcal{N}_0\\right) $$\nwhere $\\mathcal{N}_0$ is the set of the $K$ training observations closest to $x_0$.\n- Informally, average together the $K$ \"closest\" observations in your training set\n- \"Closeness\": usually use the **Euclidean metric** to measure distance\n- Euclidean distance between $\\mathbf{X}_i=(x_{i1}, x_{i2}, \\ldots, x_{ip})$ and $\\mathbf{x}_j=(x_{j1}, x_{j2}, \\ldots, x_{jp})$:\n$$||\\mathbf{x}_i-\\mathbf{x}_j||_2 = \\sqrt{(x_{i1}-x_{j1})^2 + (x_{i2}-x_{j2})^2 + \\ldots + (x_{ip}-x_{jp    })^2}$$\n\n## [KNN Regression (single predictor): Fit]{.r-fit-text} {.smaller}\n\n::::{.columns}\n:::{.column}\n**$K=1$**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)   # load the caret package\nknnfit1 <- knnreg(profit ~ population, data = outlets, k = 1)   # 1-nn regression\npredict(knnfit1, newdata = data.frame(population = 6))  # 1-nn prediction\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.92695\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](04-MultipleRegression_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n:::{.column}\n**$K=5$**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknnfit5 <- knnreg(profit ~ population, data = outlets, k = 5)   # 5-nn regression\npredict(knnfit5, newdata = data.frame(population = 6))  # 5-nn prediction\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.76995\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](04-MultipleRegression_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n## Regression Methods: Comparison\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04-MultipleRegression_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n\n## <span style=\"color:blue\">Question!!!</span>\n\nAs $K$ in KNN regression increases:\n\n- the flexibility of the fit $\\underline{\\hspace{5cm}}$ ([increases]{.fragment .highlight-red} /decreases)\n- the bias of the fit $\\underline{\\hspace{5cm}}$ (increases/[decreases]{.fragment .highlight-red} )\n- the variance of the fit $\\underline{\\hspace{5cm}}$ ([increases]{.fragment .highlight-red}/decreases)\n\n\n## [K-Nearest Neighbors Regression (multiple predictors)]{.r-fit-text} {.smaller}\n\n- Let's look at the `house_prices` data\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 3\n  Sale_Price Gr_Liv_Area Bedroom_AbvGr\n       <int>       <int>         <int>\n1     215000        1656             3\n2     105000         896             2\n3     172000        1329             3\n4     244000        2110             3\n5     189900        1629             3\n6     195500        1604             3\n```\n\n\n:::\n:::\n\n\n:::{.fragment}\n:::{.incremental}\n- Should 1 square foot count the same as 1 bedroom?\n- Need to **center and scale** (freq. just say scale) \n  + subtract mean from each predictor\n  + divide by standard deviation of each predictor\n  + compares apples-to-apples\n:::\n:::\n\n## Scaling in R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# scale predictors\names_scaled <- tibble(size_scaled = scale(ames$Gr_Liv_Area),\n                                  num_bedrooms_scaled = scale(ames$Bedroom_AbvGr),\n                                  price = ames$Sale_Price)\n\nhead(ames_scaled)   # first six observations\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 3\n  size_scaled[,1] num_bedrooms_scaled[,1]  price\n            <dbl>                   <dbl>  <int>\n1           0.309                   0.176 215000\n2          -1.19                   -1.03  105000\n3          -0.338                   0.176 172000\n4           1.21                    0.176 244000\n5           0.256                   0.176 189900\n6           0.206                   0.176 195500\n```\n\n\n:::\n:::\n\n\n\n\n## [K-Nearest Neighbors Regression (multiple predictors)]{.r-fit-text} {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknnfit10 <- knnreg(price ~ size_scaled + num_bedrooms_scaled, data = ames_scaled, k = 10)   # 10-nn regression\n```\n:::\n\n\n\n- Must also scale test data points **using mean and sd from training set!!!!**\n- Test Point: `size` = 2000 square feet, and `num_bedrooms` = 3, then\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# obtain 10-nn prediction\n\npredict(knnfit10, newdata = tibble(size_scaled = (2000 - mean(ames$Gr_Liv_Area))/sd(ames$Gr_Liv_Area),\n                                     num_bedrooms_scaled = (3 - mean(ames$Bedroom_AbvGr))/sd(ames$Bedroom_AbvGr)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 259490\n```\n\n\n:::\n:::\n\n\n\n\n## [Linear Regression vs K-Nearest Neighbors]{.r-fit-text} {.smaller}\n\n- Linear regression is a parametric approach (with restrictive assumptions), KNN is non-parametric.\n- Linear regression works for regression problems ($Y$ numerical), KNN can be used for both regression and classification - i.e. $Y$ qualitative (next lesson)\n- Linear regression is interpretable, KNN is not.\n- Linear regression can accommodate qualitative predictors and can be extended to include interaction terms as well while KNN does not allow for qualitative predictors\n- Performance: KNN can be pretty good for small $p$, that is, $p \\le 4$ and large $n$. Performance of KNN deteriorates as $p$ increases - *curse of dimensionality*\n\n<!-- ## Classification Problems {.smaller} -->\n\n<!-- - Response $Y$ is qualitative (categorical). -->\n<!-- - Objective: build a classifier $\\hat{Y}=\\hat{C}(\\mathbf{X})$ -->\n<!--   + assigns class label to a future unlabeled (unseen) observations  -->\n<!--   + understand the relationship between the predictors and response -->\n<!-- - Two ways to make predictions -->\n<!--   + Class probabilities  -->\n<!--   + Class labels -->\n\n<!-- ## Classification Problems: Example -->\n\n<!-- **Default dataset** -->\n\n<!-- ```{r, message=FALSE} -->\n<!-- library(ISLR2)   # load library -->\n<!-- data(\"Default\")   # load dataset -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- head(Default)   # print first six observations -->\n<!-- ``` -->\n\n<!-- ```{r,message=FALSE} -->\n<!-- table(Default$default)   # class frequencies -->\n<!-- ``` -->\n\n\n<!-- **We will consider `default` as the response variable.** -->\n\n\n<!-- ## Classification Problems: Example -->\n\n<!-- For some algorithms, we might need to convert the categorical response to numeric (0/1) values. -->\n\n<!-- **Default dataset** -->\n\n<!-- ```{r,message=FALSE} -->\n<!-- Default$default_id <- ifelse(Default$default == \"Yes\", 1, 0)   # create 0/1 variable -->\n\n<!-- head(Default, 10)   # print first ten observations -->\n<!-- ``` -->\n\n\n\n\n<!-- ## K-Nearest Neighbors Classifier -->\n\n<!-- Given a value for $K$ and a test data point $x_0$, -->\n<!-- $$P(Y=j | X=x_0)=\\dfrac{1}{K} \\sum_{x_i \\in \\mathcal{N}_0} I(y_i = j)$$ -->\n\n<!-- where $\\mathcal{N}_0$ is known as the **neighborhood** of $x_0$. -->\n\n\n<!-- For classification problems, the predictions are obtained in terms of **majority vote** (unlike in regression where predictions are obtained by averaging). -->\n\n\n<!-- ## K-Nearest Neighbors Classifier: Build Model  -->\n\n<!-- **Default dataset** -->\n\n<!-- response ($Y$): `default` and predictor ($X$): `balance` -->\n\n<!-- ```{r} -->\n<!-- library(caret)   # load package 'caret' -->\n\n<!-- knnfit <- knn3(default ~ balance, data = Default, k = 10)   # fit 10-nn model -->\n<!-- ``` -->\n\n\n<!-- ## K-Nearest Neighbors Classifier: Predictions  -->\n\n<!-- **Default dataset** -->\n\n<!-- * One can directly obtain the class label predictions as below. -->\n\n<!-- ```{r} -->\n<!-- knn_class_preds_1 <- predict(knnfit, newdata = Default, type = \"class\")   # obtain default class label predictions -->\n<!-- ``` -->\n\n\n<!-- * Otherwise, one can first obtain predictions in terms of probabilities and then convert them into class label predictions based on a threshold. -->\n\n<!-- ```{r} -->\n<!-- knn_prob_preds <- predict(knnfit, newdata = Default, type = \"prob\")   # obtain predictions as probabilities -->\n<!-- ``` -->\n\n\n<!-- ```{r} -->\n<!-- threshold <- 0.5   # set threshold -->\n\n<!-- knn_class_preds_2 <- factor(ifelse(knn_prob_preds[,2] > threshold, \"Yes\", \"No\"))   # obtain predictions as class labels -->\n<!-- ``` -->\n\n\n<!-- ## K-Nearest Neighbors Classifier: Performance  {.smaller} -->\n\n<!-- **Default dataset** -->\n\n<!-- ```{r} -->\n<!-- # create confusion matrix -->\n\n<!-- # use the following code only when all predictions are from the same class -->\n<!-- # levels(knn_class_preds_1) = c(\"No\", \"Yes\")  -->\n\n<!-- confusionMatrix(data = knn_class_preds_1, reference = Default$default, positive = \"Yes\")    -->\n<!-- ``` -->\n\n\n",
    "supporting": [
      "04-MultipleRegression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}