{
  "hash": "d119e20a35aca85606fb9d505fde992d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'MAT-427: Data Splitting + KNN'\nauthor: Eric Friedlander\nfooter: \"[ðŸ”— MAT 427 - Spring 2025 -  Schedule](https://mat427sp25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\n---\n\n\n\n\n\n## Computational Setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(readODS)\nlibrary(modeldata) # contains ames dataset\n\ntidymodels_prefer()\n\nmlr_model <- linear_reg() |> \n  set_engine(\"lm\")\n```\n:::\n\n\n\n\n## Comparing Models: Data Splitting {.smaller}\n\n- Split `ames` data set into two parts\n  + Training set: randomly selected proportion $p$ (typically 50-90%) of data used for fitting model\n  + Test set: randomly selected proportion $1-p$ of data used for estimating prediction error\n- If comparing A LOT of models, split into *three* parts to prevent **information leakage**\n  + Training set: randomly selected proportion $p$ (typically 50-90%) of data used for fitting model\n  + Validation set: randomly selected proportion $q$ (typically 20-30%) of data used to choosing tuning parameters\n  + Test set: randomly selected proportion $1-p-q$ of data used for estimating prediction error\n- Idea: use data your model hasn't seen to get more accurate estimate of error and prevent overfitting\n\n## Comparing Models: Data Splitting with `tidymodels` {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(427) # Why?\n\names_split <- initial_split(ames, prop = 0.70, strata = Sale_Price) # initialize 70/30\names_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<2049/881/2930>\n```\n\n\n:::\n\n```{.r .cell-code}\names_train <- training(ames_split) # get training data\names_test <- testing(ames_split) # get test data\n```\n:::\n\n\n\n\n- `strata` not necessary but good practice\n  + `strata` will use *stratified sampling* on the variable you specify (very little downside) \n\n## Linear Regression: Comparing Models {.smaller}\n\n- Let's create three models with `Sale_Price` as the response:\n  + **fit1**: a linear regression model with `Bedroom_AbvGr`  as the only predictor\n  + **fit2**: a linear regression model with `Gr_Liv_Area` as the only predictor\n  + **fit3** (similar to model in previous slides): a multiple regression model with `Gr_Liv_Area` and `Bedroom_AbvGr` as predictors\n  + **fit4**: super flexible model which fits a 10th degree polynomial to `Gr_Liv_Area` and a 2nd degree polynomial to `Bedroom_AbvGr`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- mlr_model |> fit(Sale_Price ~ Bedroom_AbvGr, data = ames_train) # Use only training set\nfit2 <- mlr_model |> fit(Sale_Price ~ Gr_Liv_Area, data = ames_train)\nfit3 <- mlr_model |> fit(Sale_Price ~ Gr_Liv_Area + Bedroom_AbvGr, data = ames_train)\nfit4 <- mlr_model |> fit(Sale_Price ~ poly(Gr_Liv_Area, degree = 10) + poly(Bedroom_AbvGr, degree = 2), data = ames_train)\n```\n:::\n\n\n\n\n## Computing MSE {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit 1\nfit1_train_mse <- mean((ames_train$Sale_Price - predict(fit1, new_data = ames_train)$.pred)^2)\nfit1_test_mse <- mean((ames_test$Sale_Price - predict(fit1, new_data = ames_test)$.pred)^2)\n\n# Fit 2\nfit2_train_mse <- mean((ames_train$Sale_Price - predict(fit2, new_data = ames_train)$.pred)^2)\nfit2_test_mse <- mean((ames_test$Sale_Price - predict(fit2, new_data = ames_test)$.pred)^2)\n\n# Fit \nfit3_train_mse <- mean((ames_train$Sale_Price - predict(fit3, , new_data = ames_train)$.pred)^2)\nfit3_test_mse <- mean((ames_test$Sale_Price - predict(fit3, new_data = ames_test)$.pred)^2)\n\n# Fit \nfit4_train_mse <- mean((ames_train$Sale_Price - predict(fit4, , new_data = ames_train)$.pred)^2)\nfit4_test_mse <- mean((ames_test$Sale_Price - predict(fit4, new_data = ames_test)$.pred)^2)\n```\n:::\n\n\n\n\n## [Question]{style=\"color:blue\"}\n\nWithout looking at the numbers\n\n1. Do we know which of the following is the smallest: `fit1_train_mse`, `fit2_train_mse`, `fit3_train_mse`, `fit4_train_mse`? [Yes, `fit4_train_mse`]{.fragment .fade-in}\n2. Do we know which of the following is the smallest: `fit1_test_mse`, `fit2_test_mse`, `fit3_test_mse`, `fit4_test_mse`? [No]{.fragment .fade-in}\n\n## Choosing a Model {.smaller}\n\n::::{.columns}\n:::{.column}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Training Errors\nc(fit1_train_mse, fit2_train_mse, \n  fit3_train_mse, fit4_train_mse)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6213135279 3188099910 2781293767 2472424544\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.min(c(fit1_train_mse, fit2_train_mse, \n            fit3_train_mse, fit4_train_mse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\n# test Errors\nc(fit1_test_mse, fit2_test_mse, \n  fit3_test_mse, fit4_test_mse)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.329031e+09 3.203895e+09 2.732389e+09 2.726084e+12\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.min(c(fit1_test_mse, fit2_test_mse, \n            fit3_test_mse, fit4_test_mse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n:::\n\n\n\n:::\n:::{.column}\n- `fit4` has the lowest training MSE (to be expected)\n- `fit3` has the lowest test MSE\n  + We would choose `fit3`\n- Anything else interesting we see?\n:::\n::::\n\n# K-Nearest Neighbors\n\n## Regression: Conditional Averaging {.smaller}\n\n**Restaurant Outlets Profit dataset**\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-knn_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n\n\nWhat is a good value of $\\hat{f}(x)$ (expected profit), say at $x=6$?\n\nA possible choice is the **average of the observed responses** at $x=6$. But we may not observe responses for certain $x$ values.\n\n\n## K-Nearest Neighbors (KNN) Regression  {.smaller}\n\n- Non-parametric approach\n- Formally: Given a value for $K$ and a test data point $x_0$,\n$$\\hat{f}(x_0)=\\dfrac{1}{K} \\sum_{x_i \\in \\mathcal{N}_0} y_i=\\text{Average} \\ \\left(y_i \\ \\text{for all} \\ i:\\ x_i \\in \\mathcal{N}_0\\right) $$\nwhere $\\mathcal{N}_0$ is the set of the $K$ training observations closest to $x_0$.\n- Informally, average together the $K$ \"closest\" observations in your training set\n- \"Closeness\": usually use the **Euclidean metric** to measure distance\n- Euclidean distance between $\\mathbf{X}_i=(x_{i1}, x_{i2}, \\ldots, x_{ip})$ and $\\mathbf{x}_j=(x_{j1}, x_{j2}, \\ldots, x_{jp})$:\n$$||\\mathbf{x}_i-\\mathbf{x}_j||_2 = \\sqrt{(x_{i1}-x_{j1})^2 + (x_{i2}-x_{j2})^2 + \\ldots + (x_{ip}-x_{jp    })^2}$$\n\n## [KNN Regression (single predictor): Fit]{.r-fit-text} {.smaller}\n\n::::{.columns}\n:::{.column}\n**$K=1$**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknnfit1 <- nearest_neighbor(neighbors = 1) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"regression\") |> \n  fit(profit ~ population, data = outlets)   # 1-nn regression\npredict(knnfit1, new_data = tibble(population = 6)) |> kable()  # 1-nn prediction\n```\n\n::: {.cell-output-display}\n\n\n|   .pred|\n|-------:|\n| 0.92695|\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-knn_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n\n\n:::\n:::{.column}\n**$K=5$**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknnfit5 <- nearest_neighbor(neighbors = 5) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"regression\") |> \n  fit(profit ~ population, data = outlets)   # 1-nn regression\npredict(knnfit5, new_data = tibble(population = 6)) |> kable()  # 1-nn prediction\n```\n\n::: {.cell-output-display}\n\n\n|    .pred|\n|--------:|\n| 4.113736|\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-knn_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n:::\n::::\n\n## Regression Methods: Comparison\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](05-knn_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n\n\n## <span style=\"color:blue\">Question!!!</span>\n\nAs $K$ in KNN regression increases:\n\n- the flexibility of the fit ([increases]{.fragment .highlight-red} /decreases)\n- the bias of the fit (increases/[decreases]{.fragment .highlight-red} )\n- the variance of the fit ([increases]{.fragment .highlight-red}/decreases)\n\n\n## [K-Nearest Neighbors Regression (multiple predictors)]{.r-fit-text} {.smaller}\n\n- Let's look at the `house_prices` data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\names |>\n  select(Sale_Price, Gr_Liv_Area, Bedroom_AbvGr) |>\n  head() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| Sale_Price| Gr_Liv_Area| Bedroom_AbvGr|\n|----------:|-----------:|-------------:|\n|     215000|        1656|             3|\n|     105000|         896|             2|\n|     172000|        1329|             3|\n|     244000|        2110|             3|\n|     189900|        1629|             3|\n|     195500|        1604|             3|\n\n\n:::\n:::\n\n\n\n:::{.fragment}\n:::{.incremental}\n- Should 1 square foot count the same as 1 bedroom?\n- Need to **center and scale** (freq. just say scale)\n  + subtract mean from each predictor\n  + divide by standard deviation of each predictor\n  + compares apples-to-apples\n:::\n:::\n\n## Scaling in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# scale predictors\names_scaled <- tibble(size_scaled = scale(ames$Gr_Liv_Area),\n                                  num_bedrooms_scaled = scale(ames$Bedroom_AbvGr),\n                                  price = ames$Sale_Price)\n\nhead(ames_scaled) |> kable()  # first six observations\n```\n\n::: {.cell-output-display}\n\n\n| size_scaled| num_bedrooms_scaled|  price|\n|-----------:|-------------------:|------:|\n|   0.3092123|           0.1760642| 215000|\n|  -1.1942232|          -1.0320576| 105000|\n|  -0.3376606|           0.1760642| 172000|\n|   1.2073172|           0.1760642| 244000|\n|   0.2558008|           0.1760642| 189900|\n|   0.2063456|           0.1760642| 195500|\n\n\n:::\n:::\n\n\n\n\n## Question...\n\n:::{.incremental}\n-   What about the training and test sets?\n-   Need to scale BOTH sets based on the mean and standard deviation of the training set...\n-   Discussion: Why?\n-   Discussion: Why don't I need to center and scale `Sale_Price`?\n:::\n\n## Scaling Revisited\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\names_train_scaled <- tibble(size_scaled = scale(ames_train$Gr_Liv_Area),\n                                  num_bedrooms_scaled = scale(ames_train$Bedroom_AbvGr),\n                                  price = ames_train$Sale_Price)\n\names_test_scaled <- tibble(size_scaled = (ames_test$Gr_Liv_Area - mean(ames_train$Gr_Liv_Area)/sd(ames_train$Gr_Liv_Area)),\n                                  num_bedrooms_scaled = (ames_test$Bedroom_AbvGr - mean(ames_train$Bedroom_AbvGr))/sd(ames_train$Bedroom_AbvGr),\n                                  price = ames_test$Sale_Price)\n```\n:::\n\n\n\n\n-   Next time: using `recipe`'s in `tidymodels` to simplify this process\n\n## [K-Nearest Neighbors Regression (multiple predictors)]{.r-fit-text} {.smaller}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknnfit10 <- nearest_neighbor(neighbors = 10) |>   # 10-nn regression\n  set_engine(\"kknn\") |> \n  set_mode(\"regression\") |> \n  fit(price ~ size_scaled + num_bedrooms_scaled, data = ames_train_scaled)\n```\n:::\n\n\n\n\n- Test Point: `Gr_Liv_area` = 2000 square feet, and `Bedroom_AbvGr` = 3, then\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# obtain 10-nn prediction\n\npredict(knnfit10, new_data = tibble(size_scaled = (2000 - mean(ames_train$Gr_Liv_Area))/sd(ames_train$Gr_Liv_Area),\n                                     num_bedrooms_scaled = (3 - mean(ames_train$Bedroom_AbvGr))/sd(ames_train$Bedroom_AbvGr)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 1\n   .pred\n   <dbl>\n1 256380\n```\n\n\n:::\n:::\n\n\n\n\n\n## [Linear Regression vs K-Nearest Neighbors]{.r-fit-text} {.smaller}\n\n- Linear regression is a parametric approach (with restrictive assumptions), KNN is non-parametric.\n- Linear regression works for regression problems ($Y$ numerical), KNN can be used for both regression and classification - i.e. $Y$ qualitative\n- Linear regression is interpretable, KNN is not.\n- Linear regression can accommodate qualitative predictors and can be extended to include interaction terms as well while KNN does not allow for qualitative predictors\n- Performance: KNN can be pretty good for small $p$, that is, $p \\le 4$ and large $n$. Performance of KNN deteriorates as $p$ increases - *curse of dimensionality*\n\n## Classification Problems {.smaller}\n\n- Response $Y$ is qualitative (categorical).\n- Objective: build a classifier $\\hat{Y}=\\hat{C}(\\mathbf{X})$\n  + assigns class label to a future unlabeled (unseen) observations\n  + understand the relationship between the predictors and response\n- Two ways to make predictions\n  + Class probabilities\n  + Class labels\n\n## Default Dataset {.smaller}\n\n\nA simulated data set containing information on ten thousand customers. The aim here is to predict which customers will default on their credit card debt.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ISLR2)   # load library\nhead(Default) |> kable()  # print first six observations\n```\n\n::: {.cell-output-display}\n\n\n|default |student |   balance|    income|\n|:-------|:-------|---------:|---------:|\n|No      |No      |  729.5265| 44361.625|\n|No      |Yes     |  817.1804| 12106.135|\n|No      |No      | 1073.5492| 31767.139|\n|No      |No      |  529.2506| 35704.494|\n|No      |No      |  785.6559| 38463.496|\n|No      |Yes     |  919.5885|  7491.559|\n\n\n:::\n:::\n\n\n\n\n## Summarizing our response variable\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(janitor)\nDefault |> tabyl(default) |> kable()  # class frequencies\n```\n\n::: {.cell-output-display}\n\n\n|default |    n| percent|\n|:-------|----:|-------:|\n|No      | 9667|  0.9667|\n|Yes     |  333|  0.0333|\n\n\n:::\n:::\n\n\n\n\nWe will consider `default` as the response variable.\n\n## Data Types in R {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDefault |> glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 10,000\nColumns: 4\n$ default <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, Noâ€¦\n$ student <fct> No, Yes, No, No, No, Yes, No, Yes, No, No, Yes, Yes, No, No, Nâ€¦\n$ balance <dbl> 729.5265, 817.1804, 1073.5492, 529.2506, 785.6559, 919.5885, 8â€¦\n$ income  <dbl> 44361.625, 12106.135, 31767.139, 35704.494, 38463.496, 7491.55â€¦\n```\n\n\n:::\n:::\n\n\n\n\n-   `fct` = `factor` which is the data type you want to use for categorical data\n-   `as_factor` will typically transform things (including numbers) into factors for you\n-   `chr` can also be used but `factor`s are better because they store all possible levels for your categorical data\n-   `factor`s are helpful for plotting because you can reorder the levels to help you plot things\n\n## K-Nearest Neighbors Classifier\n\nGiven a value for $K$ and a test data point $x_0$,\n$$P(Y=j | X=x_0)=\\dfrac{1}{K} \\sum_{x_i \\in \\mathcal{N}_0} I(y_i = j)$$\n\nwhere $\\mathcal{N}_0$ is known as the **neighborhood** of $x_0$.\n\n\nFor classification problems, the predictions are obtained in terms of **majority vote** (unlike in regression where predictions are obtained by averaging).\n\n\n## K-Nearest Neighbors Classifier: Build Model\n\n**Default dataset**\n\nresponse ($Y$): `default` and predictor ($X$): `balance`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_default_fit <- nearest_neighbor(neighbors = 10) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"classification\") |> \n  fit(default ~ balance, data = Default)   # fit 10-nn model\n```\n:::\n\n\n\n\n\n## K-Nearest Neighbors Classifier: Predictions\n\n-   `predict` with a categorical response: [documentation](https://parsnip.tidymodels.org/reference/predict.model_fit.html)\n-   Two different ways of making predictions\n\n## Predicting a class\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_class_preds <- predict(knn_default_fit, new_data = Default, type = \"class\")   # obtain default class label predictions\n\nknn_class_preds |> head() |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|.pred_class |\n|:-----------|\n|No          |\n|No          |\n|No          |\n|No          |\n|No          |\n|No          |\n\n\n:::\n:::\n\n\n\n\n##  Predicting a probability\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_prob_preds <- predict(knn_default_fit, new_data = Default, type = \"prob\")   # obtain predictions as probabilities\nknn_prob_preds |> filter(.pred_No*.pred_Yes >0) |> head() |> kable()\n```\n\n::: {.cell-output-display}\n\n\n| .pred_No| .pred_Yes|\n|--------:|---------:|\n|   0.9855|    0.0145|\n|   0.8030|    0.1970|\n|   0.9345|    0.0655|\n|   0.9855|    0.0145|\n|   0.9855|    0.0145|\n|   0.6565|    0.3435|\n\n\n:::\n:::\n\n\n\n\n## Questions\n\n-   How do you think the probabilities are calculated?\n-   How do you think we get from the probabilities to the class predictions?\n-   Can you think of a situation in which you might choose a different way of going to probabilities to class labels?\n\n## Thresholds\n\n-   Can convert probabilities to classifications\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthreshold <- 0.5   # set threshold\n\nknn_class_preds_2 <- factor(if_else(knn_prob_preds$.pred_Yes > threshold, \"Yes\", \"No\"))   # obtain predictions as class labels\nknn_class_preds_2 |> tabyl()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n knn_class_preds_2    n percent\n                No 9833  0.9833\n               Yes  167  0.0167\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n-   What if the downside of default is REALLY BAD \n\n## Thresholds\n\n-   Can convert probabilities to classifications\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthreshold <- 0.2   # set threshold\n\nknn_class_preds_3 <- factor(if_else(knn_prob_preds$.pred_Yes > threshold, \"Yes\", \"No\"))   # obtain predictions as class labels\nknn_class_preds_3 |> tabyl()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n knn_class_preds_3    n percent\n                No 9464  0.9464\n               Yes  536  0.0536\n```\n\n\n:::\n:::\n\n\n\n\n\n<!-- ## K-Nearest Neighbors Classifier: Performance  {.smaller} -->\n\n<!-- **Default dataset** -->\n\n<!-- ```{r} -->\n<!-- # create confusion matrix -->\n\n<!-- # use the following code only when all predictions are from the same class -->\n<!-- # levels(knn_class_preds_1) = c(\"No\", \"Yes\") -->\n\n<!-- confusionMatrix(data = knn_class_preds_1, reference = Default$default, positive = \"Yes\") -->\n<!-- ``` -->\n\n\n",
    "supporting": [
      "05-knn_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}